# -*- coding: utf-8 -*-
"""TP8_IOS1_Maxime_Bourgeois.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/143RqQ3aknXzYotCH81xZ2nGqGvmJQilo

#WEEK 8
Written by Maxime BOURGEOIS

#PART 1: Autoencoder and Denoising Autoencoder on MNIST Dataset

#PART 2 (Exe.18): Colorization of Black and White Images on Labeled Faces in the Wild Dataset

#Deep Autoencoder on MNIST
"""

import numpy as np
import tensorflow as tf

from tensorflow import keras

from tensorflow.keras.layers import Input

from keras.datasets import mnist

import matplotlib.pyplot as plt

"""##Exe. 1: Import the mnist dataset from the keras.datasets

Load it in x train, y train, x test, y test variables. Check the train and test shapes.
"""

(x_train, _), (x_test, _) = mnist.load_data()

print(x_train.shape)
print(x_test.shape)

x_train_0 = plt.imshow(x_train[0])
plt.gray()
plt.show()

"""###Normalize x train and x test"""

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# normalize to range 0-1
x_train = x_train / 255.0
x_test = x_test / 255.0

print(x_train.shape)
print(x_test.shape)
print(x_train[0].shape)

"""## Exe. 2: Plot some images to see your normalization results"""

x_train_1 = plt.imshow(x_train[0])
plt.gray()
plt.show()

"""##Exe. 3: Encoder Model

###Let's define the LATENT SIZE = 32
"""

LATENT_SIZE = 32

x_train = x_train.reshape(len(x_train), np.prod(x_train.shape[1:]))
x_test = x_test.reshape(len(x_test), np.prod(x_test.shape[1:]))

"""###Create a encoder model namely encoder

Dense => ReLU => Dropout => Dense => ReLU => Dropout => Dense => ReLU => Dropout => Dense => ReLU => Dropout
"""

encoder = keras.Sequential()

encoder.add(keras.layers.Dense(512, activation ='relu'))
encoder.add(keras.layers.Dropout(0.2))

encoder.add(keras.layers.Dense(128, activation ='relu'))
encoder.add(keras.layers.Dropout(0.2))

encoder.add(keras.layers.Dense(64, activation ='relu'))
encoder.add(keras.layers.Dropout(0.2))

encoder.add(keras.layers.Dense(LATENT_SIZE, activation ='relu'))
encoder.add(keras.layers.Dropout(0.2))

"""##Exe. 4: Create a decoder model namely decoder"""

decoder = keras.Sequential()

decoder.add(keras.layers.Dense(64, activation ='relu'))
decoder.add(keras.layers.Dropout(0.2))

decoder.add(keras.layers.Dense(128, activation ='relu'))
decoder.add(keras.layers.Dropout(0.2))

decoder.add(keras.layers.Dense(512, activation ='relu'))
decoder.add(keras.layers.Dropout(0.2))

decoder.add(keras.layers.Dense(784, activation='sigmoid'))

"""##Exe. 5: Compile the Model"""

img = Input(shape=(784,))

latent_vector = encoder(img)
output = decoder(latent_vector)

model = keras.Model(inputs = img, outputs = output)

model.summary()

model.compile("nadam", loss= "binary_crossentropy")

"""##Exe. 6 Train the Model"""

EPOCHS = 60
for epoch in range(EPOCHS):
  print('EPOCH nÂ°', epoch+1)
  model.fit(x_train, x_train)

  rand = x_test[np.random.randint(0, 10000, 16)].reshape((4, 4, 1, 784))

  
  for i in range(4):
    for j in range(4):
      ax = plt.subplot(4, 4, i*4 + 1 + j)
      ax.get_xaxis().set_visible(False)
      ax.get_yaxis().set_visible(False)
      plt.gray()
      imgg = model.predict(rand[i, j]).reshape(28, 28)
      plt.imshow(imgg)

 
  plt.show()

"""###How close is it to the original images?"""

plt.figure(figsize=(40, 4))
for i in range(10):

    # display original images
    ax = plt.subplot(2, 10, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
    # display reconstructed images
    ax = plt.subplot(2, 10, 10 + i + 1)

    imgg = model.predict(x_test[i].reshape(1, 784))
    plt.imshow(imgg.reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
  
    
plt.show()

"""#Denoising autoencoder on MNIST

##Exe. 7: Generate corrupted MNIST images (Add noise)

Generate corrupted MNIST images by adding noise with normal dis-
tribution (mean = 0.5 and std= 0.5) to your x train and x test dataset. Fix
the random seed with your student number.
"""

(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

np.random.seed(703782)

x_train_noisy = x_train + np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)
x_test_noisy = x_test + np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)

print(x_train_noisy.shape)
print(x_test_noisy.shape)

"""##Exe. 8: np.clip()

After adding the random generated noises to the x sets, keep only those among 0 and 1 using np.clip()
"""

x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

"""##Exe. 9: Noisy image plots

Print some of your noisy images to see how they are noisy now.
"""

for i in range(3):

  ax = plt.subplot(1, 3, i+1)

  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  plt.imshow(x_train_noisy[i])


plt.show()

"""##Exe. 10: Noisy vs Real Image

Check the new noisy data with the previous model. How are the results? How they are close to the real images?
"""

def get_ax(index):
  ax = plt.subplot(3, 3, index+1)
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
  return ax

def plot_noisy_vs_real(data_index):

  ax = get_ax(0)
  plt.title("Noisy Image")
  plt.imshow(x_test_noisy[data_index].reshape(28,28))

  ax = get_ax(1)
  plt.title("Noisy Image Prediction")
  imgg = model.predict(x_test_noisy[data_index].reshape(1, 784))
  plt.imshow(imgg.reshape(28, 28))

  ax = get_ax(2)
  plt.title("Real Image")
  plt.imshow(x_test[data_index].reshape(28, 28))

  plt.show()


plot_noisy_vs_real(0)
plot_noisy_vs_real(1)
plot_noisy_vs_real(2)

"""**Conclusion : Predictions for noisy images are very bad.**

## Exe. 11: New encoder Model 

The model is as following:

Input(Inputshape) => Conv2d(32) => Conv2d(64) => Flatten => Dense(Latent vector size)
"""

print(x_train[0].shape)
print(x_test[0].shape)
print(x_train_noisy[0].shape)
print(x_test_noisy[0].shape)

"""We need a shape like (28, 28, 1) and not (28, 28)"""

def resize_img(data):
  image_size = data.shape[1]
  data = np.reshape(data, [-1, image_size, image_size, 1])
  return data

x_train = resize_img(x_train)
x_test = resize_img(x_test)

x_train_noisy = resize_img(x_train_noisy)
x_test_noisy = resize_img(x_test_noisy)

print(x_train[0].shape)
print(x_test[0].shape)
print(x_train_noisy[0].shape)
print(x_test_noisy[0].shape)

LATENT_SIZE = 16

encoder = keras.Sequential()

encoder.add(keras.layers.Input(shape=(28, 28, 1)))
encoder.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))
encoder.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))
      
encoder.add(keras.layers.Flatten())

encoder.add(keras.layers.Dense(LATENT_SIZE, activation='relu'))

"""##Exe. 12: Build decoder model, based on the following model:


Input(latent size) => Dense(28 * 28 * 1) => Conv2DTranspose(64) =>
 Conv2DTranspose(32) => Conv2DTranspose => Activation('sigmoid')
"""

decoder = keras.Sequential()

#decoder.add(keras.layers.Input(shape=(LATENT_SIZE,)))


decoder.add(keras.layers.Dense(784, activation='relu'))

decoder.add(keras.layers.Reshape(target_shape=(28, 28, 1)))

decoder.add(keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), activation='relu', padding='same', strides=1))

decoder.add(keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), activation='relu', padding='same', strides=1))

decoder.add(keras.layers.Conv2DTranspose(1, kernel_size=(3, 3), activation='sigmoid', padding='same'))

"""##Exe. 13: Make the final model including the encoder and decoder models"""

input = Input(shape=(28 , 28, 1))
latent_vector = encoder(input)

output = decoder(latent_vector)
print(output.shape)

autoencoder = keras.Model(inputs=input, outputs = output, name ='autoencoder')

encoder.summary()
decoder.summary()
autoencoder.summary()

"""## Exe. 14: Compile the model 


using two classical 'mse' loss function and 'adam' optimiser
"""

autoencoder.compile("adam", loss= "mse")

"""## Exe. 15: Now train the autoencoder. Notice that the to be trained data
here is x train noisy, while the exact data is x train. It is the same for the
test data set:
"""

autoencoder.fit(x_train_noisy, x_train, validation_data=(x_test_noisy, x_test), epochs =30, batch_size = 128)

"""## Exe. 16: predict the x test noisy using the trained autoencoder model."""

predicted = autoencoder.predict(x_test_noisy)

"""##Exe. 17: Get some of the x test, x test noisy and predicted x test noisy
from the trained model and show compare them in dierent gures.
"""

def get_ax(index):
  ax = plt.subplot(3, 3, index+1)
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
  return ax

def plot_noisy_vs_real(data_index):

  ax = get_ax(0)
  plt.title("Noisy Image")
  plt.imshow(x_test_noisy[data_index].reshape(28, 28))

  ax = get_ax(1)
  plt.title("Noisy Image Prediction")
  plt.imshow(predicted[data_index].reshape(28, 28))

  ax = get_ax(2)
  plt.title("Real Image")
  plt.imshow(x_test[data_index].reshape(28, 28))

  plt.show()


plot_noisy_vs_real(0)
plot_noisy_vs_real(1)
plot_noisy_vs_real(2)

"""#Exe. 18: Implement an encoder decoder on Labeled Faces in the Wild dataset

###Import Libraries
"""

from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras

from keras.layers import Conv2D, Dense, Flatten, Conv2DTranspose, Input, Reshape
from keras import backend

"""###Load Data"""

def load_data():

    global training_data, testing_data

    lfw_people = fetch_lfw_people(min_faces_per_person=1, resize=0.7, color=True)

     

    h = lfw_people.images.shape[1]
    w = lfw_people.images.shape[2]
    d = lfw_people.images.shape[3]


    xs = lfw_people.data
    ys = lfw_people.target

    x_train, x_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2)

    return (x_train, x_test, y_train, y_test, h, w, d)

"""###Check Data Shape"""

x_train, x_test, y_train, y_test, h, w, d = load_data()

print(x_train)
print(x_train.shape)
print(h)
print(w)
print(d)

"""###Get Gray Dataset"""

reshape_before_gray_train = np.asarray(tf.reshape(x_train, [x_train.shape[0], h, w, d]))
x_train_gray = np.array(tf.image.rgb_to_grayscale(reshape_before_gray_train))

reshape_before_gray_test = np.asarray(tf.reshape(x_test, [x_test.shape[0], h, w, d]))
x_test_gray = np.array(tf.image.rgb_to_grayscale(reshape_before_gray_test))

"""###Scale Data"""

x_train = x_train.astype('float32')/255.0
x_test = x_test.astype('float32')/255.0

x_train_gray = x_train_gray.astype('float32')/255.0
x_test_gray = x_test_gray.astype('float32')/255.0

"""### Resize Data"""

def resize_data(x, size, deph):
  x = tf.reshape(x, [x.shape[0], h, w, deph])
  x = tf.image.resize(images=x, size=size, preserve_aspect_ratio=False)

  return x


x_train = np.array(resize_data(x_train, [56,56], 3))
x_test = np.array(resize_data(x_test, [56,56], 3))

x_train_gray = np.array(resize_data(x_train_gray, [56,56], 1))
x_test_gray = np.array(resize_data(x_test_gray, [56,56], 1))

"""###Plot RGB Image"""

plt.imshow(x_train[0].reshape(56,56,3))
plt.axis('off')
plt.show()
print(x_train[0].shape)

"""###Plot Gray Image"""

plt.imshow(x_train_gray[0].reshape(56, 56))
plt.gray()
plt.axis('off')
plt.show()

print(x_train_gray[0].shape)

"""###LATENT_SIZE Definition"""

LATENT_SIZE = 256
kernel_size=(3, 3)

"""###Encoder Model"""

encoder = keras.Sequential()

encoder.add(keras.layers.Input(shape=(56, 56, 1)))

encoder.add(keras.layers.Conv2D(64, kernel_size, activation='relu', padding='same', strides=2))
encoder.add(keras.layers.Conv2D(128, kernel_size, activation='relu', padding='same', strides=2))
encoder.add(keras.layers.Conv2D(256, kernel_size, activation='relu', padding='same', strides=2))

encoder.add(keras.layers.Flatten())

encoder.add(keras.layers.Dense(LATENT_SIZE, activation='relu'))

"""###Decoder Model"""

decoder = keras.Sequential()

decoder.add(keras.layers.Input(shape=(LATENT_SIZE,)))

decoder.add(keras.layers.Dense(12544, activation='relu'))
decoder.add(keras.layers.Reshape(target_shape=(7, 7, 256)))


decoder.add(keras.layers.Conv2DTranspose(256, kernel_size=kernel_size, activation='relu', padding='same', strides=2))
decoder.add(keras.layers.Conv2DTranspose(128, kernel_size=kernel_size, activation='relu', padding='same', strides=2))
decoder.add(keras.layers.Conv2DTranspose(64, kernel_size=kernel_size, activation='relu', padding='same', strides=2))

decoder.add(keras.layers.Conv2DTranspose(3, kernel_size=kernel_size, activation='sigmoid', padding='same'))

"""###AutoEncoder Model"""

input = Input(shape=(56,56, 1))
latent_vector = encoder(input)

output = decoder(latent_vector)
print(output.shape)

autoencoder = keras.Model(inputs=input, outputs = output, name ='autoencoder')

encoder.summary()
decoder.summary()
autoencoder.summary()

"""###Compile the Model"""

autoencoder.compile(optimizer='adam', loss='mse')

"""###Fit the Model"""

autoencoder.fit(x_train_gray, 
                x_train, 
                validation_data =(x_test_gray, x_test), 
                epochs = 200, 
                batch_size = 128)

"""###Get prediction on test dataset"""

predicted = autoencoder.predict(x_test_gray)

"""###Plot the results"""

def get_ax(index):
  ax = plt.subplot(3, 3, index+1)
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
  return ax

def plot_gray_vs_colored_vs_real(data_index):

  ax = get_ax(0)
  plt.title("Gray Image")
  plt.imshow(x_test_gray[data_index].reshape(56,56))

  ax = get_ax(1)
  plt.title("Colored Image Prediction")
  plt.imshow(predicted[data_index].reshape(56,56, 3))

  ax = get_ax(2)
  plt.title("Real Image")
  plt.imshow(x_test[data_index].reshape(56,56, 3))

  plt.show()


for i in range(15):
  plot_gray_vs_colored_vs_real(i)


j = 11
plt.title("Gray Image")
plt.imshow(x_test_gray[j].reshape(56,56))
plt.show()

plt.title("Colored Image Prediction")
plt.imshow(predicted[j].reshape(56,56, 3))
plt.show()

plt.title("Real Image")
plt.imshow(x_test[j].reshape(56,56, 3))
plt.show()

"""###Conclusion

Pretty good result !

This could be explained by a lack of samples in the dataset.
"""